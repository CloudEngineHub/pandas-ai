---
title: 'NL Layer'
description: 'Understanding the AI and natural language processing capabilities of PandaAI'
---

## How does PandaAI NL Layer work?

The Natural Language Layer uses generative AI to transform natural language queries into production-ready code generated by LLMs.
When you use the `.chat` method on a [semantic dataframe](/v3/dataframes), PandaAI passes to the LLM the question, the table headers, and 5-10 rows of the Dataframe.
It then instructs the LLM to generate the most relevant code, whether Python or SQL. The code is then executed locally.
There are different output formats supported by PandaAI, which can be found [here](/v3/output-formats).

The NL Layer is also one of the core components of our [Data Platform](/v3/ai-dashboards), which allows you to turn raw data into collaborative AI dashboards with in-built conversational agents with a single line of code.
```python
df.load("organization/dataset-name")
df.push()
```

## Configure the NL Layer

PandaAI allows you to configure the NL Layer with the `config.set()` method.

Example:

```python
import pandasai as pai

pai.config.set({
   "llm": "openai",
   "save_logs": True,
   "verbose": False,
   "enable_cache": True,
   "max_retries": 3
})
```

### Parameters

#### llm
- **Description**: The LLM to use. You can pass an instance of an LLM or the name of an LLM. See [supported LLMs](/v3/large-language-models) for setup instructions and configuration options.

#### save_logs
- **Type**: `bool`
- **Default**: `True`
- **Description**: Whether to save the logs of the LLM. You will find the logs in the `pandasai.log` file in the root of your project.

#### verbose
- **Type**: `bool`
- **Default**: `False`
- **Description**: Whether to print the logs in the console as PandaAI is executed.

#### enable_cache
- **Type**: `bool`
- **Default**: `True`
- **Description**: Whether to enable caching. If set to True, PandaAI will cache the results of the LLM to improve the response time. If set to False, PandaAI will always call the LLM. Learn more about [caching](/v3/chat-and-cache#cache).

#### max_retries
- **Type**: `int`
- **Default**: `3`
- **Description**: The maximum number of retries to use when using the error correction framework. You can use this setting to override the default number of retries.
